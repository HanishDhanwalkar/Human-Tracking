{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_CJAyRJNFXK"
      },
      "source": [
        "## **Developing tool for detecting and counting unique people/characters in a movie clip**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "collapsed": true,
        "id": "4Ks2yLk1NTh6",
        "outputId": "dddc22ee-cca1-4659-f841-bbbcf5f42e3e"
      },
      "outputs": [],
      "source": [
        "# # for multi-object tracking algorithm\n",
        "# ! pip install deepsort \n",
        "# # for object detection\n",
        "# ! pip install opencv-python "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tNRx5A-yNBw9"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import deepsort\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "net = cv.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
        "# net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
        "# net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img = cv.imread('imgs/1.jpg')\n",
        "cv.imshow('win', img)\n",
        "cv.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254 ('conv_0', 'bn_0', 'leaky_1', 'conv_1', 'bn_1', 'leaky_2', 'conv_2', 'bn_2', 'leaky_3', 'conv_3', 'bn_3', 'leaky_4', 'shortcut_4', 'conv_5', 'bn_5', 'leaky_6', 'conv_6', 'bn_6', 'leaky_7', 'conv_7', 'bn_7', 'leaky_8', 'shortcut_8', 'conv_9', 'bn_9', 'leaky_10', 'conv_10', 'bn_10', 'leaky_11', 'shortcut_11', 'conv_12', 'bn_12', 'leaky_13', 'conv_13', 'bn_13', 'leaky_14', 'conv_14', 'bn_14', 'leaky_15', 'shortcut_15', 'conv_16', 'bn_16', 'leaky_17', 'conv_17', 'bn_17', 'leaky_18', 'shortcut_18', 'conv_19', 'bn_19', 'leaky_20', 'conv_20', 'bn_20', 'leaky_21', 'shortcut_21', 'conv_22', 'bn_22', 'leaky_23', 'conv_23', 'bn_23', 'leaky_24', 'shortcut_24', 'conv_25', 'bn_25', 'leaky_26', 'conv_26', 'bn_26', 'leaky_27', 'shortcut_27', 'conv_28', 'bn_28', 'leaky_29', 'conv_29', 'bn_29', 'leaky_30', 'shortcut_30', 'conv_31', 'bn_31', 'leaky_32', 'conv_32', 'bn_32', 'leaky_33', 'shortcut_33', 'conv_34', 'bn_34', 'leaky_35', 'conv_35', 'bn_35', 'leaky_36', 'shortcut_36', 'conv_37', 'bn_37', 'leaky_38', 'conv_38', 'bn_38', 'leaky_39', 'conv_39', 'bn_39', 'leaky_40', 'shortcut_40', 'conv_41', 'bn_41', 'leaky_42', 'conv_42', 'bn_42', 'leaky_43', 'shortcut_43', 'conv_44', 'bn_44', 'leaky_45', 'conv_45', 'bn_45', 'leaky_46', 'shortcut_46', 'conv_47', 'bn_47', 'leaky_48', 'conv_48', 'bn_48', 'leaky_49', 'shortcut_49', 'conv_50', 'bn_50', 'leaky_51', 'conv_51', 'bn_51', 'leaky_52', 'shortcut_52', 'conv_53', 'bn_53', 'leaky_54', 'conv_54', 'bn_54', 'leaky_55', 'shortcut_55', 'conv_56', 'bn_56', 'leaky_57', 'conv_57', 'bn_57', 'leaky_58', 'shortcut_58', 'conv_59', 'bn_59', 'leaky_60', 'conv_60', 'bn_60', 'leaky_61', 'shortcut_61', 'conv_62', 'bn_62', 'leaky_63', 'conv_63', 'bn_63', 'leaky_64', 'conv_64', 'bn_64', 'leaky_65', 'shortcut_65', 'conv_66', 'bn_66', 'leaky_67', 'conv_67', 'bn_67', 'leaky_68', 'shortcut_68', 'conv_69', 'bn_69', 'leaky_70', 'conv_70', 'bn_70', 'leaky_71', 'shortcut_71', 'conv_72', 'bn_72', 'leaky_73', 'conv_73', 'bn_73', 'leaky_74', 'shortcut_74', 'conv_75', 'bn_75', 'leaky_76', 'conv_76', 'bn_76', 'leaky_77', 'conv_77', 'bn_77', 'leaky_78', 'conv_78', 'bn_78', 'leaky_79', 'conv_79', 'bn_79', 'leaky_80', 'conv_80', 'bn_80', 'leaky_81', 'conv_81', 'permute_82', 'yolo_82', 'identity_83', 'conv_84', 'bn_84', 'leaky_85', 'upsample_85', 'concat_86', 'conv_87', 'bn_87', 'leaky_88', 'conv_88', 'bn_88', 'leaky_89', 'conv_89', 'bn_89', 'leaky_90', 'conv_90', 'bn_90', 'leaky_91', 'conv_91', 'bn_91', 'leaky_92', 'conv_92', 'bn_92', 'leaky_93', 'conv_93', 'permute_94', 'yolo_94', 'identity_95', 'conv_96', 'bn_96', 'leaky_97', 'upsample_97', 'concat_98', 'conv_99', 'bn_99', 'leaky_100', 'conv_100', 'bn_100', 'leaky_101', 'conv_101', 'bn_101', 'leaky_102', 'conv_102', 'bn_102', 'leaky_103', 'conv_103', 'bn_103', 'leaky_104', 'conv_104', 'bn_104', 'leaky_105', 'conv_105', 'permute_106', 'yolo_106')\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1199: error: (-213:The function/feature is not implemented) The library is compiled without QT support in function 'cv::displayOverlay'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblob\u001b[39m\u001b[38;5;124m'\u001b[39m, r)\n\u001b[0;32m      9\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlob shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblob\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m cv\u001b[38;5;241m.\u001b[39mdisplayOverlay(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblob\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m     11\u001b[0m cv\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m net\u001b[38;5;241m.\u001b[39msetInput(blob)\n",
            "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1199: error: (-213:The function/feature is not implemented) The library is compiled without QT support in function 'cv::displayOverlay'\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "ln = net.getLayerNames()\n",
        "print(len(ln), ln)\n",
        "\n",
        "# construct a blob from the image\n",
        "blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "r = blob[0, 0, :, :]\n",
        "\n",
        "cv.imshow('blob', r)\n",
        "text = f'Blob shape={blob.shape}'\n",
        "cv.displayOverlay('blob', text)\n",
        "cv.waitKey(1)\n",
        "\n",
        "net.setInput(blob)\n",
        "t0 = time.time()\n",
        "outputs = net.forward(ln)\n",
        "t = time.time()\n",
        "\n",
        "cv.displayOverlay('window', f'forward propagation time={t-t0}')\n",
        "cv.imshow('window',  img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'deepsort' has no attribute 'Tracker'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tracker \u001b[38;5;241m=\u001b[39m deepsort\u001b[38;5;241m.\u001b[39mTracker()\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'deepsort' has no attribute 'Tracker'"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "G1ZwkzwdNRgV",
        "outputId": "11cf60ff-921e-42eb-a2a8-992eee99b756"
      },
      "outputs": [
        {
          "ename": "error",
          "evalue": "OpenCV(4.10.0) /io/opencv/modules/dnn/src/darknet/darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'readNetFromDarknet'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-be2857a80bd9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov3.cfg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yolov3.weights\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Load YOLO model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepsort\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define RoI and crossing line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/dnn/src/darknet/darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: yolov3.cfg in function 'readNetFromDarknet'\n"
          ]
        }
      ],
      "source": [
        "net = cv.dnn.readNet(\"yolov3.cfg\", \"yolov3.weights\") # Load YOLO model\n",
        "\n",
        "tracker = deepsort.Tracker()\n",
        "\n",
        "# Define RoI and crossing line\n",
        "roi = (x1, y1, x2, y2)\n",
        "crossing_line = (x_line, y_line)\n",
        "\n",
        "# Load video\n",
        "cap = cv2.VideoCapture(\"your_video.mp4\")\n",
        "\n",
        "# Initialize counters\n",
        "total_count = 0\n",
        "counted_ids = set()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Crop frame to RoI\n",
        "    cropped_frame = frame[y1:y2, x1:x2]\n",
        "\n",
        "    # Detect objects\n",
        "    blob = cv2.dnn.blobFromImage(cropped_frame, 1/255, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward()\n",
        "\n",
        "    # Get detections\n",
        "    class_ids = []\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5 and class_id == 0:  # Assuming 'person' is class 0\n",
        "                center_x, center_y, width, height = int(detection[0] * cropped_frame.shape[1]), int(detection[1] * cropped_frame.shape[0]), int(detection[2] * cropped_frame.shape[1]), int(detection[3] * cropped_frame.shape[0])\n",
        "                x, y = int(center_x - width / 2), int(center_y - height / 2)\n",
        "                boxes.append([x, y, width, height])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Track objects\n",
        "    tracks = tracker.update(np.array(boxes), np.array(confidences), np.array(class_ids))\n",
        "\n",
        "    # Count objects that cross the line\n",
        "    for track in tracks:\n",
        "        if track.is_confirmed() and track.get_centroid()[1] > crossing_line[1] and track.track_id not in counted_ids:\n",
        "            total_count += 1\n",
        "            counted_ids.add(track.track_id)\n",
        "\n",
        "    # Visualize\n",
        "    # ... (draw bounding boxes, crossing line, and count)\n",
        "\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(\"Total count:\", total_count)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

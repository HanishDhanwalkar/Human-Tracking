{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-11-3 Python-3.11.7 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(r'C:/Users/Hanish/.cache/torch/hub/ultralytics_yolov5_master', 'custom', path='yolov5s.pt', force_reload=True, source='local') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hanish\\\\Desktop\\\\IE643'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(os.path.realpath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hanish\\\\Desktop\\\\IE643\\\\main'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.realpath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Hanish\\\\Desktop\\\\IE643'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.path.realpath('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloDectector():\n",
    "    def __init__(self, model_name) -> None:\n",
    "        self.model = self.load_model(model_name)\n",
    "        self.classes = self.model.names\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print('Using {} device'.format(self.device))\n",
    "        \n",
    "    def load_model(self, model_name):\n",
    "        if model_name:\n",
    "            model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_name, force_reload=True)\n",
    "        else:\n",
    "            model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def score_frame(self, frame):\n",
    "        self.model.to(self.device)\n",
    "        downscale_factor = 2\n",
    "        width = int(frame.shape[1] / downscale_factor)\n",
    "        height = int(frame.shape[0] / downscale_factor)\n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        \n",
    "        results = self.model(frame)\n",
    "        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
    "        return labels, cord\n",
    "    \n",
    "    def class_to_label(self, x):\n",
    "        return self.classes[int(x)]\n",
    "    \n",
    "    def plot_boxes(self, results, frame, height, width, confidence):\n",
    "        labels, cord = results\n",
    "        detections = []\n",
    "        \n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = width, height\n",
    "        \n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            \n",
    "            if row[4] >= confidence:\n",
    "                x1,  y1, x2, y2 = int(row[0] * x_shape), int(row[1] * y_shape), int(row[2] * x_shape),int(row[3] * y_shape)\n",
    "\n",
    "                if self.class_to_label(labels[i]) == 'person':\n",
    "                    x_center = x1 + (x2 - x1)/2\n",
    "                    y_center = y1 + (y2 - y1)/2\n",
    "                    \n",
    "                    tlwh = np.array([x1, y1, int(x2-x1), int(y2-y1)], dtype=np.float32)\n",
    "                    confidence = float(row[4].item())\n",
    "                    feature = 'person'\n",
    "                    \n",
    "                    detections.append(([x1, y1, int(x2-x1), int(y2-y1)], row[4].item(), 'person'))\n",
    "                    \n",
    "        return frame, detections\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # from camera\n",
    "# video_path = \"sample_vids/1.mp4\"  \n",
    "# cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Hanish/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2024-11-3 Python-3.11.7 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "detector = YoloDectector(model_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pip install deepsort for object tracking\n",
    "\n",
    "# ! pip install deep_sort_realtime -q --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_tracker = DeepSort(\n",
    "                max_age=5, # allow tracker to miss up to this many frames before discarding bounding box/track\n",
    "                n_init=2, # initialises 2 frames \n",
    "                nms_max_overlap=1.0,\n",
    "                max_cosine_distance=0.3,\n",
    "                ### Deafults settings:\n",
    "                # nn_budget=None,\n",
    "                # override_track_class=None,\n",
    "                # embedder=\"mobilenet\",\n",
    "                # half=True,\n",
    "                # bgr=True,\n",
    "                # embedder_gpu= True,\n",
    "                # embedder_model_name=None,\n",
    "                # polygon=False,\n",
    "                # today=None\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    results = detector.score_frame(img)\n",
    "    img, detections = detector.plot_boxes(results, img, height=img.shape[0], width=img.shape[1], confidence=0.5)\n",
    "    \n",
    "    tracks = object_tracker.update_tracks(detections, frame=img)\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed() or track.time_since_update > 1:\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        \n",
    "        bbox = ltrb\n",
    "        cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255,0,0), 2)\n",
    "        cv2.putText(img, \"ID: \" + str(track_id), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0), 2)\n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    fps = 1 / (end - start)\n",
    "    \n",
    "    cv2.putText(img, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "    cv2.imshow('output', img)\n",
    "    \n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720) \n",
    "    \n",
    "    detector = YoloDectector(model_name=None)\n",
    "    os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "    \n",
    "    object_tracker = DeepSort(\n",
    "                max_age=5, # allow tracker to miss up to this many frames before discarding bounding box/track\n",
    "                n_init=2, # initialises 2 frames \n",
    "                nms_max_overlap=1.0,\n",
    "                max_cosine_distance=0.3,\n",
    "                ### Deafults settings:\n",
    "                # nn_budget=None,\n",
    "                # override_track_class=None,\n",
    "                # embedder=\"mobilenet\",\n",
    "                # half=True,\n",
    "                # bgr=True,\n",
    "                # embedder_gpu= True,\n",
    "                # embedder_model_name=None,\n",
    "                # polygon=False,\n",
    "                # today=None\n",
    "                )\n",
    "    \n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        ret, img = cap.read()\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        results = detector.score_frame(img)\n",
    "        img, detections = detector.plot_boxes(results, img, height=img.shape[0], width=img.shape[1], confidence=0.5)\n",
    "        \n",
    "        tracks = object_tracker.update_tracks(detections, frame=img)\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            track_id = track.track_id\n",
    "            ltrb = track.to_ltrb()\n",
    "            \n",
    "            bbox = ltrb\n",
    "            cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (255,0,0), 2)\n",
    "            cv2.putText(img, \"ID: \" + str(track_id), (int(bbox[0]), int(bbox[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0), 2)\n",
    "            \n",
    "        end = time.perf_counter()\n",
    "        fps = 1 / (end - start)\n",
    "        \n",
    "        cv2.putText(img, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "        cv2.imshow('output', img)\n",
    "        \n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

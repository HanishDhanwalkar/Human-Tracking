{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './imgs/1.jpg'\n",
    "image = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 770)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Width = image.shape[1]\n",
    "Height = image.shape[0]\n",
    "Height,Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.00392\n",
    "# classes = ['person', 'tree', 'crosswalk']\n",
    "classes = ['person',\n",
    "'bicycle',\n",
    "'car',\n",
    "'motorcycle',\n",
    "'airplane',\n",
    "'bus',\n",
    "'train',\n",
    "'truck',\n",
    "'boat',\n",
    "'traffic light',\n",
    "'fire hydrant',\n",
    "'stop sign',\n",
    "'parking meter',\n",
    "'bench',\n",
    "'bird',\n",
    "'cat',\n",
    "'dog',\n",
    "'horse',\n",
    "'sheep',\n",
    "'cow',\n",
    "'elephant',\n",
    "'bear',\n",
    "'zebra',\n",
    "'giraffe',\n",
    "'backpack',\n",
    "'umbrella',\n",
    "'handbag',\n",
    "'tie',\n",
    "'suitcase',\n",
    "'frisbee',\n",
    "'skis',\n",
    "'snowboard',\n",
    "'sports ball',\n",
    "'kite',\n",
    "'baseball bat',\n",
    "'baseball glove',\n",
    "'skateboard',\n",
    "'surfboard',\n",
    "'tennis racket',\n",
    "'bottle',\n",
    "'wine glass',\n",
    "'cup',\n",
    "'fork',\n",
    "'knife',\n",
    "'spoon',\n",
    "'bowl',\n",
    "'banana',\n",
    "'apple',\n",
    "'sandwich',\n",
    "'orange',\n",
    "'broccoli',\n",
    "'carrot',\n",
    "'hot dog',\n",
    "'pizza',\n",
    "'donut',\n",
    "'cake',\n",
    "'chair',\n",
    "'couch',\n",
    "'potted plant',\n",
    "'bed',\n",
    "'dining table',\n",
    "'toilet',\n",
    "'tv',\n",
    "'laptop',\n",
    "'mouse',\n",
    "'remote',\n",
    "'keyboard',\n",
    "'cell phone',\n",
    "'microwave',\n",
    "'oven',\n",
    "'toaster',\n",
    "'sink',\n",
    "'refrigerator',\n",
    "'book',\n",
    "'clock',\n",
    "'vase',\n",
    "'scissors',\n",
    "'teddy bear',\n",
    "'hair drier',\n",
    "'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate different colors for different classes \n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO\n",
    "net = cv2.dnn.readNet('yolov3.cfg', 'yolov3.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input blob \n",
    "blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input blob for the network\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    try:\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    except:\n",
    "        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = net.forward(get_output_layers(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n",
    "# for each detetion from each output layer \n",
    "# get the confidence, class id, bounding box params\n",
    "# and ignore weak detections (confidence < 0.5)\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    # print('class_id: ',class_id)\n",
    "    label = str(classes[class_id])\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "for i in indices:\n",
    "    try:\n",
    "        # print(1)\n",
    "        box = boxes[i]\n",
    "        class_id = class_ids[i]\n",
    "    except:\n",
    "        # print(2)\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        class_id = class_ids[i]\n",
    "    \n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    draw_prediction(image, class_id, confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "\n",
    "cv2.imshow(\"object detection\", image)\n",
    "cv2.waitKey()\n",
    "    \n",
    "cv2.imwrite(\"object-detection.jpg\", image)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(str):\n",
    "    ''' this script if you want only want get the coord '''\n",
    "    # picpath = str\n",
    "    # cfg='D:/core/darknetAB/cfg/yolov3.cfg' #change this if you want use different config\n",
    "    # coco='D:/core/darknetAB/cfg/coco.data' #you can change this too\n",
    "    # data='D:/core/darknetAB/yolov3.weights' #and this, can be change by you\n",
    "    # test = scan(imagePath=picpath, thresh=0.25, configPath=cfg, weightPath=data, metaPath=coco, showImage=False, makeImageOnly=False, initOnly=False) #default format, i prefer only call the result not to produce image to get more performance\n",
    "\n",
    "    #until here you will get some data in default mode from alexeyAB, as explain in module.\n",
    "    #try to: help(scan), explain about the result format of process is: [(item_name, convidence_rate (x_center_image, y_center_image, width_size_box, height_size_of_box))], \n",
    "    #to change it with generally used form, like PIL/opencv, do like this below (still in detect function that we create):\n",
    "\n",
    "    newdata = []\n",
    "    if len(out) >=2:\n",
    "        for x in out:\n",
    "            item, confidence_rate, imagedata = x\n",
    "            x1, y1, w_size, h_size = imagedata\n",
    "            x_start = round(x1 - (w_size/2))\n",
    "            y_start = round(y1 - (h_size/2))\n",
    "            x_end = round(x_start + w_size)\n",
    "            y_end = round(y_start + h_size)\n",
    "            data = (item, confidence_rate, (x_start, y_start, x_end, y_end), w_size, h_size)\n",
    "            newdata.append(data)\n",
    "\n",
    "    # elif len(test) == 1:\n",
    "    #     item, confidence_rate, imagedata = test[0]\n",
    "    #     x1, y1, w_size, h_size = imagedata\n",
    "    #     x_start = round(x1 - (w_size/2))\n",
    "    #     y_start = round(y1 - (h_size/2))\n",
    "    #     x_end = round(x_start + w_size)\n",
    "    #     y_end = round(y_start + h_size)\n",
    "    #     data = (item, confidence_rate, (x_start, y_start, x_end, y_end), w_size, h_size)\n",
    "    #     newdata.append(data)\n",
    "\n",
    "    else:\n",
    "        newdata = False\n",
    "\n",
    "    return newdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
